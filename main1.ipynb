{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aa46d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c22976f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.layers import Conv2D,Add,MaxPooling2D, Dense, BatchNormalization,Input,Flatten, Dropout,GlobalMaxPooling2D,Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f23c6c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('./../kaggle/')\n",
    "path_train = '../kaggle/train'\n",
    "path_valid = '../kaggle/valid'\n",
    "path_test  = '../kaggle/test'\n",
    "\n",
    "train = path_train\n",
    "validation = path_valid\n",
    "test = path_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0427d33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255)#initialize train generator \n",
    "                                 \n",
    "valid_datagen = ImageDataGenerator(rescale = 1.0/255.) #initialize validation generator \n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1.0/255.) #initialize validation generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82526afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 70626 images belonging to 450 classes.\n",
      "Found 2250 images belonging to 450 classes.\n",
      "Found 2250 images belonging to 450 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train, target_size=(224,224),batch_size=32,class_mode='categorical')\n",
    "\n",
    "validation_generator = valid_datagen.flow_from_directory(validation, target_size=(224,224),batch_size=32,class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(test, target_size=(224,224),batch_size=32,class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a3a123",
   "metadata": {},
   "outputs": [],
   "source": [
    "#utilisation inception v3 pour lanalyse d'image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12163396",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-15 17:46:22.016616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87910968/87910968 [==============================] - 11s 0us/step\n"
     ]
    }
   ],
   "source": [
    "inception = tf.keras.applications.InceptionV3(weights='imagenet',include_top=False,input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d72713a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inception.trainable = True\n",
    "for layer in inception.layers[:197]:\n",
    "    layer.trainable = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a6966f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0:  input_1: trainable = False\n",
      " 1:  conv2d: trainable = False\n",
      " 2:  batch_normalization: trainable = False\n",
      " 3:  activation: trainable = False\n",
      " 4:  conv2d_1: trainable = False\n",
      " 5:  batch_normalization_1: trainable = False\n",
      " 6:  activation_1: trainable = False\n",
      " 7:  conv2d_2: trainable = False\n",
      " 8:  batch_normalization_2: trainable = False\n",
      " 9:  activation_2: trainable = False\n",
      " 10:  max_pooling2d: trainable = False\n",
      " 11:  conv2d_3: trainable = False\n",
      " 12:  batch_normalization_3: trainable = False\n",
      " 13:  activation_3: trainable = False\n",
      " 14:  conv2d_4: trainable = False\n",
      " 15:  batch_normalization_4: trainable = False\n",
      " 16:  activation_4: trainable = False\n",
      " 17:  max_pooling2d_1: trainable = False\n",
      " 18:  conv2d_8: trainable = False\n",
      " 19:  batch_normalization_8: trainable = False\n",
      " 20:  activation_8: trainable = False\n",
      " 21:  conv2d_6: trainable = False\n",
      " 22:  conv2d_9: trainable = False\n",
      " 23:  batch_normalization_6: trainable = False\n",
      " 24:  batch_normalization_9: trainable = False\n",
      " 25:  activation_6: trainable = False\n",
      " 26:  activation_9: trainable = False\n",
      " 27:  average_pooling2d: trainable = False\n",
      " 28:  conv2d_5: trainable = False\n",
      " 29:  conv2d_7: trainable = False\n",
      " 30:  conv2d_10: trainable = False\n",
      " 31:  conv2d_11: trainable = False\n",
      " 32:  batch_normalization_5: trainable = False\n",
      " 33:  batch_normalization_7: trainable = False\n",
      " 34:  batch_normalization_10: trainable = False\n",
      " 35:  batch_normalization_11: trainable = False\n",
      " 36:  activation_5: trainable = False\n",
      " 37:  activation_7: trainable = False\n",
      " 38:  activation_10: trainable = False\n",
      " 39:  activation_11: trainable = False\n",
      " 40:  mixed0: trainable = False\n",
      " 41:  conv2d_15: trainable = False\n",
      " 42:  batch_normalization_15: trainable = False\n",
      " 43:  activation_15: trainable = False\n",
      " 44:  conv2d_13: trainable = False\n",
      " 45:  conv2d_16: trainable = False\n",
      " 46:  batch_normalization_13: trainable = False\n",
      " 47:  batch_normalization_16: trainable = False\n",
      " 48:  activation_13: trainable = False\n",
      " 49:  activation_16: trainable = False\n",
      " 50:  average_pooling2d_1: trainable = False\n",
      " 51:  conv2d_12: trainable = False\n",
      " 52:  conv2d_14: trainable = False\n",
      " 53:  conv2d_17: trainable = False\n",
      " 54:  conv2d_18: trainable = False\n",
      " 55:  batch_normalization_12: trainable = False\n",
      " 56:  batch_normalization_14: trainable = False\n",
      " 57:  batch_normalization_17: trainable = False\n",
      " 58:  batch_normalization_18: trainable = False\n",
      " 59:  activation_12: trainable = False\n",
      " 60:  activation_14: trainable = False\n",
      " 61:  activation_17: trainable = False\n",
      " 62:  activation_18: trainable = False\n",
      " 63:  mixed1: trainable = False\n",
      " 64:  conv2d_22: trainable = False\n",
      " 65:  batch_normalization_22: trainable = False\n",
      " 66:  activation_22: trainable = False\n",
      " 67:  conv2d_20: trainable = False\n",
      " 68:  conv2d_23: trainable = False\n",
      " 69:  batch_normalization_20: trainable = False\n",
      " 70:  batch_normalization_23: trainable = False\n",
      " 71:  activation_20: trainable = False\n",
      " 72:  activation_23: trainable = False\n",
      " 73:  average_pooling2d_2: trainable = False\n",
      " 74:  conv2d_19: trainable = False\n",
      " 75:  conv2d_21: trainable = False\n",
      " 76:  conv2d_24: trainable = False\n",
      " 77:  conv2d_25: trainable = False\n",
      " 78:  batch_normalization_19: trainable = False\n",
      " 79:  batch_normalization_21: trainable = False\n",
      " 80:  batch_normalization_24: trainable = False\n",
      " 81:  batch_normalization_25: trainable = False\n",
      " 82:  activation_19: trainable = False\n",
      " 83:  activation_21: trainable = False\n",
      " 84:  activation_24: trainable = False\n",
      " 85:  activation_25: trainable = False\n",
      " 86:  mixed2: trainable = False\n",
      " 87:  conv2d_27: trainable = False\n",
      " 88:  batch_normalization_27: trainable = False\n",
      " 89:  activation_27: trainable = False\n",
      " 90:  conv2d_28: trainable = False\n",
      " 91:  batch_normalization_28: trainable = False\n",
      " 92:  activation_28: trainable = False\n",
      " 93:  conv2d_26: trainable = False\n",
      " 94:  conv2d_29: trainable = False\n",
      " 95:  batch_normalization_26: trainable = False\n",
      " 96:  batch_normalization_29: trainable = False\n",
      " 97:  activation_26: trainable = False\n",
      " 98:  activation_29: trainable = False\n",
      " 99:  max_pooling2d_2: trainable = False\n",
      " 100:  mixed3: trainable = False\n",
      " 101:  conv2d_34: trainable = False\n",
      " 102:  batch_normalization_34: trainable = False\n",
      " 103:  activation_34: trainable = False\n",
      " 104:  conv2d_35: trainable = False\n",
      " 105:  batch_normalization_35: trainable = False\n",
      " 106:  activation_35: trainable = False\n",
      " 107:  conv2d_31: trainable = False\n",
      " 108:  conv2d_36: trainable = False\n",
      " 109:  batch_normalization_31: trainable = False\n",
      " 110:  batch_normalization_36: trainable = False\n",
      " 111:  activation_31: trainable = False\n",
      " 112:  activation_36: trainable = False\n",
      " 113:  conv2d_32: trainable = False\n",
      " 114:  conv2d_37: trainable = False\n",
      " 115:  batch_normalization_32: trainable = False\n",
      " 116:  batch_normalization_37: trainable = False\n",
      " 117:  activation_32: trainable = False\n",
      " 118:  activation_37: trainable = False\n",
      " 119:  average_pooling2d_3: trainable = False\n",
      " 120:  conv2d_30: trainable = False\n",
      " 121:  conv2d_33: trainable = False\n",
      " 122:  conv2d_38: trainable = False\n",
      " 123:  conv2d_39: trainable = False\n",
      " 124:  batch_normalization_30: trainable = False\n",
      " 125:  batch_normalization_33: trainable = False\n",
      " 126:  batch_normalization_38: trainable = False\n",
      " 127:  batch_normalization_39: trainable = False\n",
      " 128:  activation_30: trainable = False\n",
      " 129:  activation_33: trainable = False\n",
      " 130:  activation_38: trainable = False\n",
      " 131:  activation_39: trainable = False\n",
      " 132:  mixed4: trainable = False\n",
      " 133:  conv2d_44: trainable = False\n",
      " 134:  batch_normalization_44: trainable = False\n",
      " 135:  activation_44: trainable = False\n",
      " 136:  conv2d_45: trainable = False\n",
      " 137:  batch_normalization_45: trainable = False\n",
      " 138:  activation_45: trainable = False\n",
      " 139:  conv2d_41: trainable = False\n",
      " 140:  conv2d_46: trainable = False\n",
      " 141:  batch_normalization_41: trainable = False\n",
      " 142:  batch_normalization_46: trainable = False\n",
      " 143:  activation_41: trainable = False\n",
      " 144:  activation_46: trainable = False\n",
      " 145:  conv2d_42: trainable = False\n",
      " 146:  conv2d_47: trainable = False\n",
      " 147:  batch_normalization_42: trainable = False\n",
      " 148:  batch_normalization_47: trainable = False\n",
      " 149:  activation_42: trainable = False\n",
      " 150:  activation_47: trainable = False\n",
      " 151:  average_pooling2d_4: trainable = False\n",
      " 152:  conv2d_40: trainable = False\n",
      " 153:  conv2d_43: trainable = False\n",
      " 154:  conv2d_48: trainable = False\n",
      " 155:  conv2d_49: trainable = False\n",
      " 156:  batch_normalization_40: trainable = False\n",
      " 157:  batch_normalization_43: trainable = False\n",
      " 158:  batch_normalization_48: trainable = False\n",
      " 159:  batch_normalization_49: trainable = False\n",
      " 160:  activation_40: trainable = False\n",
      " 161:  activation_43: trainable = False\n",
      " 162:  activation_48: trainable = False\n",
      " 163:  activation_49: trainable = False\n",
      " 164:  mixed5: trainable = False\n",
      " 165:  conv2d_54: trainable = False\n",
      " 166:  batch_normalization_54: trainable = False\n",
      " 167:  activation_54: trainable = False\n",
      " 168:  conv2d_55: trainable = False\n",
      " 169:  batch_normalization_55: trainable = False\n",
      " 170:  activation_55: trainable = False\n",
      " 171:  conv2d_51: trainable = False\n",
      " 172:  conv2d_56: trainable = False\n",
      " 173:  batch_normalization_51: trainable = False\n",
      " 174:  batch_normalization_56: trainable = False\n",
      " 175:  activation_51: trainable = False\n",
      " 176:  activation_56: trainable = False\n",
      " 177:  conv2d_52: trainable = False\n",
      " 178:  conv2d_57: trainable = False\n",
      " 179:  batch_normalization_52: trainable = False\n",
      " 180:  batch_normalization_57: trainable = False\n",
      " 181:  activation_52: trainable = False\n",
      " 182:  activation_57: trainable = False\n",
      " 183:  average_pooling2d_5: trainable = False\n",
      " 184:  conv2d_50: trainable = False\n",
      " 185:  conv2d_53: trainable = False\n",
      " 186:  conv2d_58: trainable = False\n",
      " 187:  conv2d_59: trainable = False\n",
      " 188:  batch_normalization_50: trainable = False\n",
      " 189:  batch_normalization_53: trainable = False\n",
      " 190:  batch_normalization_58: trainable = False\n",
      " 191:  batch_normalization_59: trainable = False\n",
      " 192:  activation_50: trainable = False\n",
      " 193:  activation_53: trainable = False\n",
      " 194:  activation_58: trainable = False\n",
      " 195:  activation_59: trainable = False\n",
      " 196:  mixed6: trainable = False\n",
      " 197:  conv2d_64: trainable = True\n",
      " 198:  batch_normalization_64: trainable = True\n",
      " 199:  activation_64: trainable = True\n",
      " 200:  conv2d_65: trainable = True\n",
      " 201:  batch_normalization_65: trainable = True\n",
      " 202:  activation_65: trainable = True\n",
      " 203:  conv2d_61: trainable = True\n",
      " 204:  conv2d_66: trainable = True\n",
      " 205:  batch_normalization_61: trainable = True\n",
      " 206:  batch_normalization_66: trainable = True\n",
      " 207:  activation_61: trainable = True\n",
      " 208:  activation_66: trainable = True\n",
      " 209:  conv2d_62: trainable = True\n",
      " 210:  conv2d_67: trainable = True\n",
      " 211:  batch_normalization_62: trainable = True\n",
      " 212:  batch_normalization_67: trainable = True\n",
      " 213:  activation_62: trainable = True\n",
      " 214:  activation_67: trainable = True\n",
      " 215:  average_pooling2d_6: trainable = True\n",
      " 216:  conv2d_60: trainable = True\n",
      " 217:  conv2d_63: trainable = True\n",
      " 218:  conv2d_68: trainable = True\n",
      " 219:  conv2d_69: trainable = True\n",
      " 220:  batch_normalization_60: trainable = True\n",
      " 221:  batch_normalization_63: trainable = True\n",
      " 222:  batch_normalization_68: trainable = True\n",
      " 223:  batch_normalization_69: trainable = True\n",
      " 224:  activation_60: trainable = True\n",
      " 225:  activation_63: trainable = True\n",
      " 226:  activation_68: trainable = True\n",
      " 227:  activation_69: trainable = True\n",
      " 228:  mixed7: trainable = True\n",
      " 229:  conv2d_72: trainable = True\n",
      " 230:  batch_normalization_72: trainable = True\n",
      " 231:  activation_72: trainable = True\n",
      " 232:  conv2d_73: trainable = True\n",
      " 233:  batch_normalization_73: trainable = True\n",
      " 234:  activation_73: trainable = True\n",
      " 235:  conv2d_70: trainable = True\n",
      " 236:  conv2d_74: trainable = True\n",
      " 237:  batch_normalization_70: trainable = True\n",
      " 238:  batch_normalization_74: trainable = True\n",
      " 239:  activation_70: trainable = True\n",
      " 240:  activation_74: trainable = True\n",
      " 241:  conv2d_71: trainable = True\n",
      " 242:  conv2d_75: trainable = True\n",
      " 243:  batch_normalization_71: trainable = True\n",
      " 244:  batch_normalization_75: trainable = True\n",
      " 245:  activation_71: trainable = True\n",
      " 246:  activation_75: trainable = True\n",
      " 247:  max_pooling2d_3: trainable = True\n",
      " 248:  mixed8: trainable = True\n",
      " 249:  conv2d_80: trainable = True\n",
      " 250:  batch_normalization_80: trainable = True\n",
      " 251:  activation_80: trainable = True\n",
      " 252:  conv2d_77: trainable = True\n",
      " 253:  conv2d_81: trainable = True\n",
      " 254:  batch_normalization_77: trainable = True\n",
      " 255:  batch_normalization_81: trainable = True\n",
      " 256:  activation_77: trainable = True\n",
      " 257:  activation_81: trainable = True\n",
      " 258:  conv2d_78: trainable = True\n",
      " 259:  conv2d_79: trainable = True\n",
      " 260:  conv2d_82: trainable = True\n",
      " 261:  conv2d_83: trainable = True\n",
      " 262:  average_pooling2d_7: trainable = True\n",
      " 263:  conv2d_76: trainable = True\n",
      " 264:  batch_normalization_78: trainable = True\n",
      " 265:  batch_normalization_79: trainable = True\n",
      " 266:  batch_normalization_82: trainable = True\n",
      " 267:  batch_normalization_83: trainable = True\n",
      " 268:  conv2d_84: trainable = True\n",
      " 269:  batch_normalization_76: trainable = True\n",
      " 270:  activation_78: trainable = True\n",
      " 271:  activation_79: trainable = True\n",
      " 272:  activation_82: trainable = True\n",
      " 273:  activation_83: trainable = True\n",
      " 274:  batch_normalization_84: trainable = True\n",
      " 275:  activation_76: trainable = True\n",
      " 276:  mixed9_0: trainable = True\n",
      " 277:  concatenate: trainable = True\n",
      " 278:  activation_84: trainable = True\n",
      " 279:  mixed9: trainable = True\n",
      " 280:  conv2d_89: trainable = True\n",
      " 281:  batch_normalization_89: trainable = True\n",
      " 282:  activation_89: trainable = True\n",
      " 283:  conv2d_86: trainable = True\n",
      " 284:  conv2d_90: trainable = True\n",
      " 285:  batch_normalization_86: trainable = True\n",
      " 286:  batch_normalization_90: trainable = True\n",
      " 287:  activation_86: trainable = True\n",
      " 288:  activation_90: trainable = True\n",
      " 289:  conv2d_87: trainable = True\n",
      " 290:  conv2d_88: trainable = True\n",
      " 291:  conv2d_91: trainable = True\n",
      " 292:  conv2d_92: trainable = True\n",
      " 293:  average_pooling2d_8: trainable = True\n",
      " 294:  conv2d_85: trainable = True\n",
      " 295:  batch_normalization_87: trainable = True\n",
      " 296:  batch_normalization_88: trainable = True\n",
      " 297:  batch_normalization_91: trainable = True\n",
      " 298:  batch_normalization_92: trainable = True\n",
      " 299:  conv2d_93: trainable = True\n",
      " 300:  batch_normalization_85: trainable = True\n",
      " 301:  activation_87: trainable = True\n",
      " 302:  activation_88: trainable = True\n",
      " 303:  activation_91: trainable = True\n",
      " 304:  activation_92: trainable = True\n",
      " 305:  batch_normalization_93: trainable = True\n",
      " 306:  activation_85: trainable = True\n",
      " 307:  mixed9_1: trainable = True\n",
      " 308:  concatenate_1: trainable = True\n",
      " 309:  activation_93: trainable = True\n",
      " 310:  mixed10: trainable = True\n"
     ]
    }
   ],
   "source": [
    "for idx, layer in enumerate(inception.layers):\n",
    "    print(f' {idx}:  {layer.name}: trainable = {layer.trainable}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9134f347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last layer output shape:  (None, 12, 12, 768)\n"
     ]
    }
   ],
   "source": [
    "last_layer = inception.get_layer('mixed7')\n",
    "\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "\n",
    "layer_output = last_layer.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1121d54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450\n"
     ]
    }
   ],
   "source": [
    "n_categories = len(os.listdir('./../kaggle/train'))# number of categories\n",
    "print(n_categories)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dfa16b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x  = BatchNormalization()(layer_output)\n",
    "x = Flatten()(layer_output)\n",
    "x = Dense(1024,activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(n_categories, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inception.inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "961df5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = RMSprop(learning_rate=0.0001), \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "577f13a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "    \n",
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d93ecf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 546/2208 [======>.......................] - ETA: 26:21:29 - loss: 5.4730 - accuracy: 0.1533"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "            train_generator,\n",
    "            validation_data = validation_generator,\n",
    "            epochs = 20,\n",
    "callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aafad2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762c1811",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='acc')\n",
    "plt.plot(history.history['val_accuracy'], label='val_acc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea1868b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4053de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf3bc68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
